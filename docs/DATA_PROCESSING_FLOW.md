# 数据处理流程详解

从爬取日线数据到最终保存处理结果的完整流程说明。

## 📊 整体流程图

```
原始日线数据 (CSV)
    ↓
[步骤1] 数据获取 (data_fetcher.py)
    ↓
原始数据文件: data/raw/<股票码>_<日期>.csv
    ↓
[步骤2] 数据预处理 (data_processor.py)
    ├─ 数据清洗
    ├─ 计算百分比变化
    ├─ 归一化处理
    ├─ 生成标签
    ├─ 创建序列
    ├─ 数据平衡
    └─ 划分训练/验证集
    ↓
处理后数据: data/processed/<股票码>_<日期>/
    ├─ train.csv / train.npz
    └─ val.csv / val.npz
    ↓
[步骤3] 模型训练 (train_lstm.py)
    ↓
训练好的模型: logs/<时间戳>_train_<股票码>_<日期>/best_model.pth
```

---

## 🔍 详细步骤说明

### 步骤1: 数据获取 (`data_fetcher.py`)

**功能**: 从akshare获取股票/ETF/期货的日线数据

**输入**:
- `stock_code`: 股票代码（如 "000001", "518880", "NI0"）
- `end_date`: 截止日期（格式: "YYYYMMDD"）

**处理过程**:
1. 尝试ETF接口 (`fund_etf_hist_em`)
2. 如果失败，尝试股票接口 (`stock_zh_a_hist`)
3. 如果还失败，尝试期货接口 (`futures_zh_daily_sina`)
4. 保存为CSV文件

**输出**: 
- 文件路径: `data/raw/<股票码>_<日期>.csv`
- 包含列: 日期、开盘、收盘、最高、最低、成交量等

**示例数据**:
```csv
日期,开盘,收盘,最高,最低,成交量
2024-01-01,10.5,10.8,11.0,10.3,1000000
2024-01-02,10.8,11.2,11.5,10.7,1200000
...
```

---

### 步骤2: 数据预处理 (`data_processor.py`)

这是核心处理步骤，包含多个子步骤：

#### 2.1 读取原始数据

```python
df = pd.read_csv(raw_data_path)  # 读取CSV文件
```

**提取关键列**:
- 日期列（用于时间序列）
- 收盘价列（价格数据）
- 成交量列（交易量数据）

#### 2.2 数据清洗

**过滤异常数据**:
```python
# 过滤成交量小于平均值10%的天数（可能是停牌或异常数据）
volume_threshold = volume_mean * 0.1
df = df[volumes >= volume_threshold]
```

**原因**: 成交量过小的日期可能是停牌、节假日或数据异常，需要过滤掉。

#### 2.3 计算百分比变化

**核心思想**: 不直接使用价格和成交量，而是使用**相对变化**，这样更有利于模型学习。

```python
# 计算后一天相对前一天的百分比变化
for i in range(len(close_prices) - 1):
    price_pct = (close_prices[i+1] - close_prices[i]) / close_prices[i]
    volume_pct = (volumes[i+1] - volumes[i]) / volumes[i]
```

**示例**:
- 第1天收盘价: 10.0
- 第2天收盘价: 10.5
- 百分比变化: (10.5 - 10.0) / 10.0 = 0.05 = 5%（涨5%）

**为什么用百分比变化？**
- 不同股票价格差异很大（10元 vs 100元）
- 百分比变化统一了量纲，便于模型学习
- 更能反映市场波动特征

#### 2.4 归一化处理

**问题**: 百分比变化的值范围可能很大（如 -10% 到 +10%），需要归一化到 [0, 1] 范围。

##### 收盘价归一化（使用分位数方法）

```python
# 使用5%和95%分位数作为边界，避免极端值影响
price_q5 = np.percentile(price_pct_change, 5)   # 5%分位数
price_q95 = np.percentile(price_pct_change, 95)  # 95%分位数
price_range = price_q95 - price_q5

# 归一化公式
price_normalized = (price_pct_change - price_q5) / price_range
price_normalized = np.clip(price_normalized, 0, 1)  # 裁剪到[0,1]
```

**为什么用分位数而不是min/max？**
- 避免极端值（如涨停/跌停）影响归一化范围
- 使分布更分散，不会太集中在0.5附近
- 更稳健的归一化方法

**示例**:
- 原始百分比变化: [-0.1, -0.05, 0, 0.05, 0.1]
- 5%分位数: -0.08, 95%分位数: 0.08
- 归一化后: [0.0, 0.19, 0.5, 0.81, 1.0]

##### 成交量归一化（使用Z-score方法）

```python
# Z-score标准化
volume_mean = volume_pct_change.mean()
volume_std = volume_pct_change.std()
volume_zscore = (volume_pct_change - volume_mean) / volume_std

# 映射到[0,1]，使均值接近0.5
volume_zscore_clipped = np.clip(volume_zscore, -3, 3)  # 裁剪到±3倍标准差
volume_normalized = (volume_zscore_clipped + 3) / 6     # 映射到[0,1]
```

**为什么用Z-score？**
- Z-score的均值是0，映射后均值接近0.5
- 使成交量分布更均匀
- 避免成交量归一化后偏离0.5太远

**示例**:
- 原始百分比变化: [-0.2, -0.1, 0, 0.1, 0.2]
- 均值: 0, 标准差: 0.14
- Z-score: [-1.43, -0.71, 0, 0.71, 1.43]
- 归一化后: [0.26, 0.38, 0.5, 0.62, 0.74]（均值≈0.5）

#### 2.5 生成标签

**标签含义**: 预测"明天"的涨跌情况

**标签规则**:
```python
if 涨跌幅 > 3%:
    标签 = 1.0  # 明显上涨
elif 涨跌幅 < -3%:
    标签 = 0.0  # 明显下跌
else:
    # 在-3%到3%之间，线性映射到0~1
    标签 = 0.5 + (涨跌幅 / 3%) * 0.5
```

**示例**:
- 涨跌幅 = +5% → 标签 = 1.0（明显涨）
- 涨跌幅 = -4% → 标签 = 0.0（明显跌）
- 涨跌幅 = +1% → 标签 = 0.5 + (1/3) * 0.5 = 0.67（小幅涨）
- 涨跌幅 = 0% → 标签 = 0.5（不涨不跌）

**为什么用连续标签而不是0/1？**
- 更细粒度的信息（0.5表示不确定）
- 模型可以学习到"小幅涨跌"的概念
- 最终分类时用0.5作为阈值

#### 2.6 创建序列数据

**核心思想**: LSTM需要时间序列输入，使用滑动窗口创建序列。

```python
# 滑动窗口：每次取60天的数据作为输入
for i in range(len(data) - 60 - 1):
    # 输入：第i天到第i+59天的数据（60天）
    close_seq = close_prices_norm[i:i+60]
    volume_seq = volumes_norm[i:i+60]
    
    # 标签：第i+60天的涨跌（预测目标）
    label = up_down[i+60]
```

**示例**（假设序列长度=5）:
```
日期      收盘价归一化  标签
Day1     0.5         -
Day2     0.6         -
Day3     0.4         -
Day4     0.7         -
Day5     0.5         -
Day6     0.8         0.7  ← 预测目标
```

**序列1**:
- 输入: [Day1, Day2, Day3, Day4, Day5] = [0.5, 0.6, 0.4, 0.7, 0.5]
- 标签: Day6的标签 = 0.7

**序列2**:
- 输入: [Day2, Day3, Day4, Day5, Day6] = [0.6, 0.4, 0.7, 0.5, 0.8]
- 标签: Day7的标签

**为什么用滑动窗口？**
- LSTM需要时间序列输入
- 每个序列包含60天的历史信息
- 模型可以学习到时间模式（趋势、周期等）

#### 2.7 数据平衡

**问题**: 涨跌数据可能不平衡（如涨的多、跌的少），导致模型偏向多数类。

**解决方法**: 下采样多数类，使两类数量相等。

```python
# 分类：>0.5视为涨，<=0.5视为跌
up_indices = np.where(labels > 0.5)[0]    # 涨的样本索引
down_indices = np.where(labels <= 0.5)[0]  # 跌的样本索引

# 取较小值作为目标数量
target_count = min(len(up_indices), len(down_indices))

# 如果涨的多，随机下采样涨的样本
if len(up_indices) > len(down_indices):
    selected_up = np.random.choice(up_indices, size=target_count)
    balanced_indices = [selected_up, down_indices]
```

**示例**:
- 平衡前: 涨1000个，跌500个
- 平衡后: 涨500个，跌500个（各50%）

**为什么需要平衡？**
- 避免模型偏向多数类
- 提高模型对少数类的识别能力
- 使训练更稳定

#### 2.8 划分训练/验证集

```python
# 使用分层采样，确保训练集和验证集中涨跌比例一致
train_indices, val_indices = train_test_split(
    indices,
    test_size=0.2,           # 验证集占20%
    random_state=42,        # 随机种子，保证可重复
    shuffle=True,           # 打乱顺序
    stratify=labels_binary  # 分层采样（保持涨跌比例）
)
```

**划分结果**:
- 训练集: 80%（用于训练模型）
- 验证集: 20%（用于评估模型性能）

**为什么分层采样？**
- 确保训练集和验证集的涨跌比例一致
- 避免验证集偏差导致评估不准确

#### 2.9 保存处理结果

**保存格式**:

1. **CSV格式** (便于查看):
```csv
起始日期,收盘价序列,成交量序列,标签
2024-01-05,"0.5,0.6,0.4,0.7,0.5","0.3,0.4,0.2,0.5,0.3",0.7
```

2. **NPZ格式** (便于训练):
```python
np.savez('train.npz',
    close_sequences=array([...]),  # 收盘价序列数组
    volume_sequences=array([...]), # 成交量序列数组
    labels=array([...]),           # 标签数组
    start_dates=[...]              # 日期列表
)
```

**保存位置**:
- `data/processed/<股票码>_<日期>/train.csv`
- `data/processed/<股票码>_<日期>/train.npz`
- `data/processed/<股票码>_<日期>/val.csv`
- `data/processed/<股票码>_<日期>/val.npz`

---

## 📈 数据流转示例

### 原始数据
```
日期        收盘价    成交量
2024-01-01  10.0     1000000
2024-01-02  10.5     1200000
2024-01-03  10.2     1100000
2024-01-04  10.8     1300000
2024-01-05  11.0     1400000
```

### 步骤1: 计算百分比变化
```
日期        收盘价变化  成交量变化
2024-01-01  NaN        NaN
2024-01-02  +5.0%      +20.0%
2024-01-03  -2.9%      -8.3%
2024-01-04  +5.9%      +18.2%
2024-01-05  +1.9%      +7.7%
```

### 步骤2: 归一化
```
日期        收盘价归一化  成交量归一化
2024-01-01  NaN          NaN
2024-01-02  0.85         0.92
2024-01-03  0.15         0.35
2024-01-04  1.00         1.00
2024-01-05  0.55         0.58
```

### 步骤3: 生成标签（假设3%阈值）
```
日期        涨跌幅    标签
2024-01-01  -        -
2024-01-02  +5.0%    1.0  (明显涨)
2024-01-03  -2.9%    0.52 (小幅跌)
2024-01-04  +5.9%    1.0  (明显涨)
2024-01-05  +1.9%    0.82 (小幅涨)
```

### 步骤4: 创建序列（假设序列长度=3）
```
序列1:
  输入: [Day1, Day2, Day3] = [NaN, 0.85, 0.15] (收盘价)
  标签: Day4的标签 = 1.0

序列2:
  输入: [Day2, Day3, Day4] = [0.85, 0.15, 1.00] (收盘价)
  标签: Day5的标签 = 0.82
```

---

## 🎯 关键设计理念

### 1. 为什么用百分比变化而不是原始价格？
- **统一量纲**: 不同股票价格差异大，百分比变化统一了尺度
- **去除趋势**: 关注相对变化而非绝对价格
- **更易学习**: 模型更容易学习到波动模式

### 2. 为什么用不同的归一化方法？
- **收盘价**: 使用分位数，避免极端值，使分布更分散
- **成交量**: 使用Z-score，使均值接近0.5，分布更均匀

### 3. 为什么用滑动窗口？
- **时间序列**: LSTM需要时间序列输入
- **历史信息**: 60天的历史包含趋势、周期等信息
- **预测目标**: 用历史预测未来

### 4. 为什么需要数据平衡？
- **避免偏向**: 防止模型偏向多数类
- **提高性能**: 提高对少数类的识别能力
- **稳定训练**: 使训练过程更稳定

---

## 📝 总结

整个处理流程的核心是：
1. **获取原始数据** → 日线价格和成交量
2. **计算相对变化** → 百分比变化（去除绝对数值影响）
3. **归一化** → 统一到[0,1]范围（便于模型学习）
4. **生成标签** → 预测目标（涨跌情况）
5. **创建序列** → 滑动窗口（时间序列输入）
6. **数据平衡** → 涨跌各50%（避免偏向）
7. **划分数据集** → 训练集和验证集（用于训练和评估）
8. **保存结果** → CSV和NPZ格式（便于使用）

每一步都有其设计目的，共同构成了一个完整的数据处理流水线。

